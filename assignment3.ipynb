{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fR352RlxWefM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Create the Decision Matrix\n",
        "data = {\n",
        "    'Model': ['BART', 'PEGASUS', 'T5', 'GPT-3', 'LED'],\n",
        "    'ROUGE-1': [44.5, 46.2, 42.8, 41.3, 43.9],  # Benefit\n",
        "    'ROUGE-2': [21.7, 23.1, 20.4, 19.8, 20.9],  # Benefit\n",
        "    'ROUGE-L': [42.0, 43.8, 40.1, 39.5, 41.3],  # Benefit\n",
        "    'Inference Time': [0.7, 0.6, 0.9, 1.2, 0.8],  # Cost\n",
        "    'Model Size': [406, 568, 850, 1500, 650],     # Cost\n",
        "    'FLOPs': [150, 180, 200, 400, 250],           # Cost\n",
        "    'Memory Usage': [4.5, 5.0, 6.0, 8.0, 5.5]     # Cost\n",
        "}\n",
        "df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Normalize the Decision Matrix\n",
        "criteria = ['ROUGE-1', 'ROUGE-2', 'ROUGE-L', 'Inference Time', 'Model Size', 'FLOPs', 'Memory Usage']\n",
        "benefit_criteria = ['ROUGE-1', 'ROUGE-2', 'ROUGE-L']\n",
        "cost_criteria = ['Inference Time', 'Model Size', 'FLOPs', 'Memory Usage']\n",
        "\n",
        "\n",
        "# Normalization\n",
        "norm_df = df.copy()\n",
        "for col in criteria:\n",
        "    if col in benefit_criteria:\n",
        "        norm_df[col] = df[col] / np.sqrt((df[col] ** 2).sum())\n",
        "    else:\n",
        "        norm_df[col] = df[col].min() / df[col]"
      ],
      "metadata": {
        "id": "CocSl64sWhsx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Apply Weights\n",
        "weights = [0.20, 0.20, 0.15, 0.15, 0.10, 0.10, 0.10]\n",
        "norm_df[criteria] = norm_df[criteria] * weights\n",
        "\n",
        "# Step 4: Determine Ideal and Negative-Ideal Solutions\n",
        "ideal_solution = norm_df[criteria].max()\n",
        "negative_ideal_solution = norm_df[criteria].min()\n",
        "\n",
        "# Step 5: Calculate Separation Measures\n",
        "norm_df['S+'] = np.sqrt(((norm_df[criteria] - ideal_solution) ** 2).sum(axis=1))\n",
        "norm_df['S-'] = np.sqrt(((norm_df[criteria] - negative_ideal_solution) ** 2).sum(axis=1))\n",
        "\n",
        "# Step 6: Calculate Closeness Coefficient\n",
        "norm_df['Closeness Coefficient'] = norm_df['S-'] / (norm_df['S+'] + norm_df['S-'])"
      ],
      "metadata": {
        "id": "MgnD3YSvWovG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Rank the Models\n",
        "result = norm_df[['Model', 'Closeness Coefficient']].sort_values(by='Closeness Coefficient', ascending=False)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TngEsNRyWsOs",
        "outputId": "02ad204a-fa2b-421e-b839-479842dfe8b1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Model  Closeness Coefficient\n",
            "0     BART               0.839756\n",
            "1  PEGASUS               0.753906\n",
            "4      LED               0.471522\n",
            "2       T5               0.393957\n",
            "3    GPT-3               0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rank_report = result.copy()\n",
        "rank_report['Rank'] = rank_report['Closeness Coefficient'].rank(ascending=False).astype(int)\n",
        "rank_report = rank_report.sort_values(by='Rank')\n",
        "\n",
        "print(\"TOPSIS Rank Report:\")\n",
        "print(rank_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUPjstM5XFEQ",
        "outputId": "3e99e9a4-dd59-4ccc-dbf3-3256c1a6203e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOPSIS Rank Report:\n",
            "     Model  Closeness Coefficient  Rank\n",
            "0     BART               0.839756     1\n",
            "1  PEGASUS               0.753906     2\n",
            "4      LED               0.471522     3\n",
            "2       T5               0.393957     4\n",
            "3    GPT-3               0.000000     5\n"
          ]
        }
      ]
    }
  ]
}